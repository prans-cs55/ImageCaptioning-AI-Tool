📸 Image Captioning AI

Generate meaningful names and captions for photos using BLIP and Gradio

🔍 Overview

This project demonstrates an AI-powered image captioning tool that converts visual information into natural language.
It enhances accessibility, content discovery, and image management by automatically generating descriptive captions.

The application leverages the BLIP model from Hugging Face
 and provides a simple Gradio web interface.

🎯 Objectives

🖼️ Build an automated captioning tool for images

🔎 Improve photo organization & searchability

🌍 Enable real-world use cases like accessibility tools, image search, and security

⚡ Features

✅ Upload or paste image URLs


✅ Generate captions with BLIP


✅ Easy-to-use Gradio interface


✅ Lightweight and beginner-friendly

🛠️ Tech Stack
✅Python 3.8+
✅Hugging Face Transformers
✅BLIP Model
✅Gradio

📦 Installation

Clone the repo

git clone https://github.com/your-username/ImageCaptioning AI Tool.git
cd image-captioning-ai


(Optional) Create a virtual environment

python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows


Install dependencies

pip install -r requirements.txt

🚀 Usage

Run the app:

python app.py


Gradio will start a local server → open in your browser:
👉 http://127.0.0.1:7860/

📸 Example
![Uploading Screenshot 2025-09-03 193434.png…]()


🎓 Learning Outcomes

By completing this project, you will learn how to:

🔬 Describe generative AI models

🧠 Implement BLIP for image captioning

🌐 Build a Gradio interface for AI apps

🤝 Contributing

Contributions are welcome! Please fork the repo and open a PR.

📜 License

Distributed under the MIT License.
